{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b88a43ff-d18b-419c-b4c4-cbcc70410e8a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting faker\n  Downloading faker-37.4.2-py3-none-any.whl.metadata (15 kB)\nRequirement already satisfied: tzdata in /databricks/python3/lib/python3.11/site-packages (from faker) (2022.1)\nDownloading faker-37.4.2-py3-none-any.whl (1.9 MB)\n\u001B[?25l   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m0.0/1.9 MB\u001B[0m \u001B[31m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\r\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m1.9/1.9 MB\u001B[0m \u001B[31m42.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n\u001B[?25hInstalling collected packages: faker\nSuccessfully installed faker-37.4.2\n\u001B[43mNote: you may need to restart the kernel using %restart_python or dbutils.library.restartPython() to use updated packages.\u001B[0m\nCollecting kafka-python\n  Downloading kafka_python-2.2.15-py2.py3-none-any.whl.metadata (10.0 kB)\nDownloading kafka_python-2.2.15-py2.py3-none-any.whl (309 kB)\nInstalling collected packages: kafka-python\nSuccessfully installed kafka-python-2.2.15\n\u001B[43mNote: you may need to restart the kernel using %restart_python or dbutils.library.restartPython() to use updated packages.\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "%run ./IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8ebeb38c-d043-46d3-a1f6-83d05e37eb92",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tabela criada com sucesso s_sensor_iot\n"
     ]
    }
   ],
   "source": [
    "#create table s_sensor_iot\n",
    "spark.sql(\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS s_sensor_iot (\n",
    "        dt_refe STRING,\n",
    "        qt_corr INT,\n",
    "        qt_corr_neg INT,\n",
    "        qt_corr_pess INT,\n",
    "        vl_max_dist DOUBLE,\n",
    "        vl_min_dist DOUBLE,\n",
    "        vl_avg_dist DOUBLE,\n",
    "        qt_corr_reuni INT,\n",
    "        qt_corr_nao_reuni INT,\n",
    "        dt_evento TIMESTAMP\n",
    "    )\n",
    "    USING delta\n",
    "\"\"\")\n",
    "print(\"Tabela criada com sucesso s_sensor_iot\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f37bc6f5-034d-45ff-acd6-07bb746e160c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#PRODUCER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "05e0072e-cfda-4db5-abb8-ed15f47858ed",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lote 2 adicionado com sucesso\n+--------------------+--------------------+------------------+------------------+-----------+\n|           sensor_id|           timestamp|       temperatura|           umidade|   latitude|\n+--------------------+--------------------+------------------+------------------+-----------+\n|574ac9fb-386f-471...|2025-07-22 23:27:...|22.719916366913697| 32.87358920821814|-52.6132355|\n|27cb4e9f-439b-4e6...|2025-07-22 23:27:...| 24.02924070404241| 71.95983726304391|  25.254700|\n|6542cd3b-1a88-4b5...|2025-07-22 23:27:...|28.778724143556275| 71.68298766657486|  9.4668905|\n|9e887b81-8290-4e7...|2025-07-22 23:27:...|27.616884598964862| 73.03918003067032|-59.6801355|\n|4abc7d21-b387-45d...|2025-07-22 23:27:...|  39.4769727678473| 67.58049827635685|-20.7874815|\n|ac7d1870-6e4e-4a0...|2025-07-22 23:27:...|41.509335806390546| 48.79750534223887|  39.720846|\n|f634ecb3-2c49-45c...|2025-07-22 23:27:...| 22.17201212860838| 31.42209178564039|  65.400651|\n|e38899dd-61e9-425...|2025-07-22 23:27:...|33.853251934078315|39.201801373600375|-75.8589655|\n|db650ee9-8bc3-476...|2025-07-22 23:27:...| 41.21787798483811| 74.64861757403254| 87.5779095|\n|54bba5f0-af33-46c...|2025-07-22 23:27:...| 29.64032928191878| 78.85951419344532| 63.0022505|\n+--------------------+--------------------+------------------+------------------+-----------+\n\n"
     ]
    }
   ],
   "source": [
    "\n",
    "fake = Faker()\n",
    "\n",
    "# Define o schema\n",
    "schema = StructType([\n",
    "    StructField(\"sensor_id\", StringType(), True),\n",
    "    StructField(\"timestamp\", TimestampType(), True),\n",
    "    StructField(\"temperatura\", DoubleType(), True),\n",
    "    StructField(\"umidade\", DoubleType(), True),\n",
    "    StructField(\"latitude\", StringType(), True)\n",
    "])\n",
    "\n",
    "# função criada para sensor data\n",
    "def gerador_sensor_data():\n",
    "    return {\n",
    "        \"sensor_id\": str(fake.uuid4()),\n",
    "        \"timestamp\": datetime.now(),  # Keep as datetime object\n",
    "        \"temperatura\": random.uniform(20, 45),\n",
    "        \"umidade\": random.uniform(30, 90),\n",
    "        \"latitude\": str(fake.latitude())\n",
    "    }\n",
    "\n",
    "# # range(n) - gera a quantidade de lotes para mostar na tela\n",
    "for i in range(2):\n",
    "    df_lote = spark.createDataFrame([gerador_sensor_data() for _ in range(10)], schema=schema)\n",
    "    df_stream = df_lote.union(df_lote)\n",
    "    print(f\"Lote {i+1} adicionado com sucesso\")\n",
    "    df_lote.show()\n",
    "    time.sleep(3)\n",
    "    clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d02d4c83-cd66-4b41-8b6b-a8113c62b203",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#CONSUMER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "509b10cc-1656-48bc-92eb-4c43fc26ec3c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_create = df_stream.withColumn(\n",
    "    \"dt_refe\", date_format(col(\"timestamp\"), \"yyyy-MM-dd\")\n",
    ").select(\n",
    "    col(\"sensor_id\"),\n",
    "    round(col(\"temperatura\"),2).alias(\"temperature\"),\n",
    "    round(col(\"umidade\"),2).alias(\"umidade\"),\n",
    "    col(\"latitude\"),\n",
    "    col(\"dt_refe\"),\n",
    ")\n",
    "\n",
    "df_create.write.mode(\"append\").format(\"delta\").saveAsTable(\"s_sensor_iot\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 6292466894925268,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "SENSOR DE DADOS IOT",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}